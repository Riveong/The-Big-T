Some of Multi armed bandit implementation  
https://github.com/Heewon-Hailey/multi-armed-bandits-for-recommendation-systems  
Library  
https://github.com/fidelity/mab2rec